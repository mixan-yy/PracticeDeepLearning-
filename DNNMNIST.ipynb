{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "bfa2528f810cff3da322be9398180dcd0a2df933deb60a6541bda4af1579a92b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import random_split, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforms.ToTensor() converts images into numbers with three color channels\n",
    "#transforms.Normalize() normalizes the tensor with a mean and std\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,))\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"testset = datasets.MNIST('MNIST', train = False,\\n                                    download = True, transform = transform\\n                                )\""
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#load MNIST dataset to the working directory, and if the file is not alreay there, download it\n",
    "trainset = datasets.MNIST('MNIST', train = True,\n",
    "                                    download = True, transform = transform\n",
    "                                  )\n",
    "'''testset = datasets.MNIST('MNIST', train = False,\n",
    "                                    download = True, transform = transform\n",
    "                                )'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and test sets\n",
    "train, test = random_split(trainset, [55000, 5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data for training, and give the batchsize accordingly\n",
    "trainloader = DataLoader(train, batch_size = 64, shuffle=True)\n",
    "testloader = DataLoader(test, batch_size = 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([64, 1, 28, 28])\ntorch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "#see the shape of the images and labels\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sequential(\n  (0): Linear(in_features=784, out_features=128, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=128, out_features=64, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=64, out_features=10, bias=True)\n  (5): LogSoftmax(dim=1)\n)\n"
     ]
    }
   ],
   "source": [
    "#create the model here \n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    #nn.Dropout(0.2),\n",
    "    nn.Linear(128,64),\n",
    "    nn.ReLU(),\n",
    "    #nn.Dropout(0.2),\n",
    "    nn.Linear(64,10),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we give the loss type and optmizer properties\n",
    "from time import time\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "time0 = time ()\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 - Training loss: 2.236738299214563\n",
      "Epoch 2 - Training loss: 2.0190170716407687\n",
      "Epoch 3 - Training loss: 1.636873779047367\n",
      "Epoch 4 - Training loss: 1.217534734481989\n",
      "Epoch 5 - Training loss: 0.9142357387515001\n",
      "Epoch 6 - Training loss: 0.7242602819620176\n",
      "Epoch 7 - Training loss: 0.6089548842158429\n",
      "Epoch 8 - Training loss: 0.5380934163581493\n",
      "Epoch 9 - Training loss: 0.4914513547753179\n",
      "Epoch 10 - Training loss: 0.45844964514984643\n",
      "Epoch 11 - Training loss: 0.43459881284209184\n",
      "Epoch 12 - Training loss: 0.41589466965822286\n",
      "Epoch 13 - Training loss: 0.4010923460125923\n",
      "Epoch 14 - Training loss: 0.38896381541393527\n",
      "Epoch 15 - Training loss: 0.3784743438279906\n",
      "Epoch 16 - Training loss: 0.3697805682067261\n",
      "Epoch 17 - Training loss: 0.3619996112792991\n",
      "Epoch 18 - Training loss: 0.3554578417608904\n",
      "Epoch 19 - Training loss: 0.348635112936067\n",
      "Epoch 20 - Training loss: 0.3432929854666771\n",
      "Epoch 21 - Training loss: 0.3380547388348468\n",
      "Epoch 22 - Training loss: 0.3332468438633653\n",
      "Epoch 23 - Training loss: 0.3283568310443052\n",
      "Epoch 24 - Training loss: 0.32385076915975225\n",
      "Epoch 25 - Training loss: 0.3200349948780481\n",
      "Epoch 26 - Training loss: 0.3159894920885563\n",
      "Epoch 27 - Training loss: 0.3124257152943417\n",
      "Epoch 28 - Training loss: 0.30909110304228093\n",
      "Epoch 29 - Training loss: 0.3057925804843043\n",
      "Epoch 30 - Training loss: 0.30279503210859243\n",
      "\n",
      "Training Time (in minutes) = 6.0543026725451154\n"
     ]
    }
   ],
   "source": [
    "#train the model here\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0],-1)\n",
    "        \n",
    "\n",
    "        #1: Feed image to the network       \n",
    "        output = model.forward(images)\n",
    "        #2: Calculate the loss\n",
    "        loss = criterion(output,labels)\n",
    "        #3: Cleaning the gradient\n",
    "        optimizer.zero_grad()\n",
    "        #4: Accumulate the partial partial derivative wet params\n",
    "        loss.backward()\n",
    "        #5: Step in the opposite direction of the gradient\n",
    "        optimizer.step()\n",
    "        #Add the loss\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(epoch+1, running_loss/len(trainloader)))\n",
    "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number Of Images Tested = 5000\n\nModel Accuracy = 0.91\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model with the test data here\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in testloader:\n",
    "  for i in range(len(labels)):\n",
    "    img = images[i].view(1, 784) #feed one image at a time\n",
    "    with torch.no_grad():\n",
    "      logps = model.forward(img) #feed the image to the forward pass    \n",
    "      ps = torch.exp(logps)      #take the exponent of the output from forward pass\n",
    "      probab = list(ps.numpy()[0]) #make a list of the number got from the forward pass\n",
    "      pred_label = probab.index(max(probab)) #predicted label\n",
    "      true_label = labels.numpy()[i] #actual label\n",
    "      if(true_label == pred_label):\n",
    "        correct_count += 1\n",
    "      all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can save the model with the command below\n",
    "torch.save(model, './my_mnist_model.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can feed a new image with right size to the network and make a prediction\n",
    "from PIL import Image\n",
    "# Image.open() can also open other image types\n",
    "img = Image.open(\"download.png\")\n",
    "# WIDTH and HEIGHT are integers\n",
    "resized_img = img.resize((28, 28))\n",
    "resized_img.save(\"resized_download.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(28, 28, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "#Check the shape of the image\n",
    "import matplotlib.pyplot as plt \n",
    "img = plt.imread('resized_download.png')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "#Convert the image to gray scale i.e: image with one channel only\n",
    "from PIL import Image\n",
    "img = Image.open(\"resized_download.png\") #for example image size : 28x28x3\n",
    "img1 = img.convert('L')  #convert a gray scale\n",
    "print(img1.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 28, 28)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "#expand one dimension\n",
    "y = np.expand_dims(img1, axis=0)\n",
    "print(y.shape)\n",
    "#y = torch.from_numpy(y)\n",
    "y = torch.tensor(y,dtype=torch.float)\n",
    "y.shape\n",
    "y = y.view(1,784)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Probability =  [8.852069e-14, 7.155863e-07, 0.9999865, 0.0, 0.0, 2.5422273e-15, 2.6654467e-26, 1.7665733e-31, 1.2805907e-05, 9.480968e-23]\nPrediction is:  2\n"
     ]
    }
   ],
   "source": [
    "#Feed the image to the network\n",
    "with torch.no_grad():\n",
    "    logps = model(y)    \n",
    "    ps = torch.exp(logps)\n",
    "    probab = list(ps.numpy()[0])\n",
    "    pred_label = probab.index(max(probab))\n",
    "print(\"Probability = \", probab)\n",
    "print(\"Prediction is: \", pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
